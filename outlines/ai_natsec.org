#+TITLE: Artificial Intelligence and National Security
#+OPTIONS: num:nil; ^:nil; ':t

* Article Details:
  + Published By: Belfer Center for Science and International Affairs
  + URL: https://is.gd/TpCMDi

* Executive Summary
  + AI research has demonstrated much more progress than anticipated over the past 5 years
    + Most of this progress has been due to machine learning
    + Experts anticipate that this progress will continue, or even accelerate
  + Most AI research advances are occurring in academia or the private sector
    + Private sector funding for AI research dwarfs the US government's spending
  + Existing capabilities in AI have significant potential for national security
  + Future AI progress has the potential to be a transformative national security technology, on par with nuclear weapons, aircraft, computers and biotech
  + Advances in AI will affect national security by driving change in: military superiority, information superiority and economic superiority
    + Military superiority: AI will create new capabilities and make existing capabilities more affordable
      + Commercially available AI technology may give weak states and non-state actors access to long-range precision strike capabilities
      + Activities that currently require lots of high-skill labor (such as Advanced Persistent Threat operations) may be automated, packaged and sold on the black market
    + Information superiority: AI will enhance the collection, analysis and creation of data
      + More sources from which to determine truth
      + Easier to craft persuasive lies
      + AI enhanced forgeries will erode the basis of trust of many institutions
    + Economic superiority: AI could drive a new industrial revolution
      + Dramatic decline in demand for labor -- might lead to up to a "third of all men between the ages of 25 and 54 being unemployed"
      + This will reshape the relationship between labor and capital
      + Growing automation could create a "resource curse" scenario for developed countries
      + Population size will become less important for national power -- small countries with highly developed AI infrastructure will punch far above their weight
  + "Lessons learned" from four prior transformative military technologies: nuclear, aerospace, cyber, biotech
    + Radical technological change begets radical government policy ideas
      + National security implications of AI will be "revolutionary", not "different"
        + /What's the difference between "different" and "revolutionary"?/
      + Governments will consider and implement radical policy measures, perhaps as radical as in the early days of nuclear weapons
        + /What radical policy measures did governments adopt in the early days of nuclear weapons?/
    + Arms races are unavoidable, but they can be managed
      + In 1899 nations voluntarily agreed to a treaty banning the use of weaponized aircraft
      + This treaty was quickly abandoned in World War 1, as the advantages of aerial bombardment proved irresistible
      + The report's authors predict something similar for artificial intelligence -- whatever treaties or agreements we have restricting or banning the use of AI in warfare will be quickly abandoned if and when an actual war breaks out
      + Instead, we should pursue goals of keeping AI "safe"
    + Government must both promote and restrain commercial activity
      + Government must recognize the inherent dual-use nature of technology 
        + British government sold the Soviet Union 45 copies of the Rolls Royce 'Nene' jet engine
        + Soviet Union reverse engineered this engine and turned it into the Klimov VK-1 which powered the MiG-15
      + The US has a huge advantage in private sector and academic AI research
      + However, the relationship between private sector, academia and the government is fraught with tension
    + Governments must formalize goals for technology safety and provide adequate resources
      + In all cases studied, safety outcomes improved when governments created formal organizations tasked with improving the safety of their technology domains
      + Organizations must have the necessary resources (human resources, money, time and political capital)
      + US should stand up a formal organization tasked with investigating and promoting AI safety across the entire government and commercial AI portfolio
    + As technology changes, so does the US's national interest
      + Declining cost and complexity of bioweapons led US to change its strategy from aggressive development to voluntary restraint
      + US has a strategic interest in shaping the cost, complexity and offense/defense balance of national security technologies
      + As with stealth aircraft, targeted investments can allow the US to affect the offense/defense balance and build a long-lasting technological edge
  + 3 goals and 11 recommendations for US national security policy with regards to AI
    + Goal: Preserve US technological leadership
      + DOD should conduct AI-focused war games in order to identify potential disruptive military innovations
      + DOD should fund long-term strategic analyses of AI technology
      + Prioritize AI R&D spending in areas that can provide sustainable advantages and mitigate key risks
      + Invest heavily in "counter-AI" capabilities for both offense and defense
    + Goal: Support peaceful use of technology
      + DARPA, IARPA, et. al. should be given increased funding for AI related basic research
      + Department of Defense should release a request for information on dual-use AI technologies
      + In-Q-Tel should be given additional resources to promote collaboration between the national security community and the commercial AI industry
    + Goal: Manage catastrophic risks
      + The National Security Council, the Defense Department and the State Department should study what AI applications the US should seek to restrict with treaties
      + The Defense Department and the Intelligence Community should establish dedicated AI safety organizations
      + DARPA should fund research on fail-safe and safety-for-performance technology for AI systems
      + NIST and the NSA should explore options for countering AI-enabled forgery

* Introduction and Project Approach
  + Over the past 5 years, researchers have achieved key milestones in AI technology significantly more quickly than expert projections
    + AlphaGo beat a human Go champion 10 years before AI was predicted to be able to do so
    + AI is starting to beat professional poker players
    + Reliable voice recognition
    + Image recognition superior to human performance
    + Defeating a former US Air Force pilot in an air-combat simulator
  + Four key drivers between the exponential growth of AI technologies
    1. Decades of exponential growth in computing performance
    2. Increased availability of large data sets upon which to train large machine learning systems
    3. Advances in the implementation of machine learning techniques
    4. Significant and rapidly increasing commercial investment
  + These trends will drive progress in AI for at least another decade
  + Most near-future progress will be around narrow AI
  + Most experts feel like general AI, AI with the scale and fluidity of a human brain, is assumed to be several decades away
  + Rapid progress in AI will most likely affect national security
    + Defense Department leaders believe that we are at an "inflection point" in AI technology
  + US government has sponsored several studies on the future of AI and its significance for national security and governance
  + However, these studies have all focused on short-term, immediate impacts; little to no work on assessing longer term, more transformative aspects of AI
  + Project approach
    1. Analyze possible technology development scenarios related to AI and explore how they might transform national security
       + Greater diversity in potential applications of AI
       + Greater analysis of the implications of advances of AI beyond the next 5 years
       + Evaluating management paradigms for AI in a historical context
    2. Evaluate prior transformative military technologies to develop "lessons learned" for designing responses to the emergence of AI
       + AI is likely to be a transformative military technology
       + On par with aircraft and nuclear weapons
       + Four prior technologies considered
         + Nuclear
         + Aerospace
         + Cyber
         + Biotech
       + For each case, focus on the early decades of the technology, when technology management strategies had to be developed under significant uncertainty
       + Evaluate the results of those efforts against the following 3 goals:
         1. Preserve US technological leadership
         2. Support peaceful uses of the technology
         3. Manage catastrophic risk
       + These goals are not always in alignment

* Part 1: The Transformative Potential of Artificial Intelligence
  + Analyze implications across three dimensions:
    1. Military superiority
    2. Information superiority
    3. Economic superiority

** Military Superiority
   + This section analyzes the impact of artificial intelligence on the military and military systems
   + Robotics and autonomy
     + Delegation of human control to autonomous systems has been on an upward trajectory since the first autonomous systems were developed in World War 2
     + The first autonomous systems were the Norden bomb sight and the V1 "buzz-bomb", which were the first systems to link computing systems to lethal force
       + /Is that so? Don't battleship fire-control systems predate those?/
     + "Fire and forget" missiles guide a missile to its target without further operator interaction following initial target selection and fire authorization
     + The US military has developed directives restricting the development of certain autonomous capabilities
     + Notably, the guidelines specify that a human always has to be "in the loop" and directly make decisions for all uses of lethal force
       + /Though, this guideline is looser than one might think/
       + /For example: look at the Aegis and Patriot air/missile defense systems/
       + /Both are designed to operate in a fully automatic mode, where the system automatically prioritizes and engages targets within a particular sphere of influence at inhuman speed/
       + /In this case, the fact that a human is "in the loop" means little, because the human won't necessarily have a chance to react and override before the system has identified and prosecuted a target/
     + The market for both commercial and military robotics is increasing exponentially and unit prices are falling significantly
     + Some are saying that robotics is poised for the same cycle of rapid price decline and adoption growth that personal computers achieved during the '80s and '90s
     + Expanded use of machine learning, combined with market growth will greatly expand robotic systems' impact upon national security
       + We're about to experience a "Cambrian explosion" of robotics
       + Improvements in utilization of machine learning technologies
       + Improvements in the ability of robots to apply these techniques to intelligently make decisions in real time based upon sensor data
     + Increased utilization of robotics and autonomous systems will augment the power of both non-state actors and nation-states
       + We've already seen this with cyber-security
       + Countries that, before, didn't have the budget to field extensive cyberwarfare capabilities can now field cyberwarfare capabilities on par with global powers
       + These capabilities are increasingly becoming affordable to the point where even non-state actors can use them
       + Robotics will allow a similar cost reduction for physical attack
     + In the short term, advances in AI will allow more autonomous robotic support to warfighters and will accelerate the shift from manned to unmanned combat missions
       + Initially, these advances will benefit large, well-funded and technologically sophisticated militaries
       + As prices decline, these advances will trickle down to less-well-funded, less-sophisticated militaries and eventually non-state actors
       + We've already seen ISIS make use of hobbyist drones to conduct attacks
       + Although advances in robotics may increase the absolute power of all actors, the relative power balance may or may not shift
     + The size, weight and power constraints that limit advanced autonomy will eventually be overcome, just as a supercomputer from the '90s is less powerful than a cell phone today
       + /I'm not so sure about this -- this seems to be another instance where people outside the technology haven't caught on to the fact that Moore's Law has ended/
       + Automobile companies expect to start selling fully autonomous vehicles in 2021
         + /I'm not so sure about this prediction either -- it's mid-2019 and I haven't seen a lot of progress lately towards full autonomy/
       + These cars will have large, power-hungry, sophisticated computers, but over time prices will fall and sizes will shrink
         + /Again, the basis for this appears to a faith in continuing progression of Moore's Law/
     + Over the medium to long term, robotic and autonomous systems are likely to match an increasing set of the technological capabilities that have been proven by nature
       + Biology is full of intelligent autonomous systems
       + Biology provides us with "existence proofs" for the potential of robotics
       + Every animal has a suite of sensors, tools for interacting with its environment, and a relatively high-speed processing and decision-making center
       + A city pigeon has more processing capability, flight agility and power efficiency than any comparable drone
       + While we don't know what the ultimate capability of robotics is, the capabilities of biological systems provide us with a set of lower-bounds
     + Over time, these capabilities will transform military power and warfare
   + Cybersecurity and Cyberwar
     + Top US national security officials believe that AI will have a transformative effect on cybersecurity and cyberwar
     + As with all automation, AI will reduce the numbers of humans required to perform specific tasks
       + During the Cold War, the East German Stasi had a staff of 102,000 surveilling a population of 17 million
       + Today, a totalitarian government can achieve full surveillance of the digital activity of a population of billions with only a few thousand staff
     + AI will be useful for bolstering cyber-defense
       + AI can automate probing for defense and monitoring cyber-systems
       + AI can be trained to automatically spot potential vulnerabilities in code
       + AI might be trained to automatically detect and respond to anomalous behavior
       + /The important thing to do is to ensure that these autonomous responses don't introduce further vulnerabilities of their own/
     + This same logic suggests that AI can also improve cyber-offense
       + Attack approaches that are currently constrained by a lack of skilled labor, might be, in the future, only constrained by capital
       + The most challenging type of cyber-attack today is the "Advanced Persistent Threat"
         + Adversary actively hunts for weaknesses in the target's security (rather than trying a specific fixed set of attacks)
         + Waits for the target to make a mistake
         + Currently this requires a large amount of highly skilled staff
         + With AI, scanning for vulnerabilities can be automated
         + In the future, a less-sophisticated state or non-state actor might be able to buy an AI-powered APT kit which provides them with the same capabilities as the NSA or GCHQ
     + In the near term, bringing AI into cyberwarfare will benefit powerful nation-state actors, but in the long term its effects on the balance of power are hard to forecast
   + Potential transformative scenarios -- ten scenarios that illustrate the transformative potential of AI on military superiority
     1. Lethal autonomous weapons form the bulk of military forces
        + As autonomous weapons have become more capable, militaries have been willing to delegate more authority to them
        + The Russian military already has a plan to make 30% of the Russian armed forces consist of remote-controlled and autonomous robotic forces by 2030
          + /Like with all Russian plans, I'll believe it when it happens/
        + Other countries facing demographic and security challenges will likely set similar goals
          + Japan
          + Israel
        + While the US has enacted restrictions on autonomous systems wielding military force, other countries and non-state actors may not exercise the same restraint
     2. Disruptive swarming platforms render some platforms obsolete
        + For the price of a single high-end combat aircraft, a military could acquire a million quadcopter drones
          + /And for the price of a single high-end fighter aircraft, a military could acquire a million World War 1 era wood and fabric biplanes too/
          + /Once again, this section presumes the cost declines and increases in sophistication that apply to computer processors will continue for computer processors and will replicate to other forms of hardware/
        + Given the continuing trend of price declines, at some point in the future, drones might cost less than some ballistic munitions
        + While these drones currently have significant limitations, they become more sophisticated every year
        + How would an aircraft carrier respond a swarm of goose-like drones?
          + A goose can cover a range of 1500 miles in 24 hours
          + What happens when an adversary launches thousands of these
          + /Three words: falcons kill geese/
          + /The problem with drones against the carrier is *exactly* the same problem as with e.g. Russian bombers swarming a carrier battle group with cruise missiles/
          + /And the solution is exactly the same: target the archers, not the arrows/
          + /If this swarm is truly autonomous, swarm members are going to be exchanging lots of data with the rest of the swarm, as they report their location and sensor readings to each other/
          + /These readings can be jammed, hacked, or used to vector in active countermeasures/
          + /If the swarm is centrally controlled, there will be a central control system which can be targeted by e.g. airstrike or cyberattack/
          + /This is what "multi-domain" battle is really about -- responding to threat in one domain with a countermeasure from another domain/
          + /In the worst case, the carrier has "combat air patrol" drones, faster and more maneuverable than the hunter drones (since they'll be operating at shorter ranges) which will detect and eliminate the hunter drones as the hunter drone attack the aircraft carrier/
        + /My prediction is that we'll actually seen military drones *increase* in price/
          + /Early aircraft were very cheap, and were often treated as disposable/
            + /Simple wood/fabric airframes/
            + /Cheap automobile or motorcycle engines/
            + /Obsolete machine guns repurposed from old ground vehicles/
            + /Unsophisticated avionics and navigation -- early aircraft only had an engine RPM meter and an altimeter; the remainder of the avionics consisted of the pilot's eyes, ears and inner ear/
          + /But under competitive pressure, aircraft have steadily become more and more sophisticated and expensive/
            + /Wood/fabric frames → metal frames/
            + /No avionics → fly-by-wire & GPS guidance/
            + /Repurposed motorcycle engines → jet engines capable of sustained supersonic flight without afterburner/
            + /Stealth & electronic countermeasures/
            + /Etc/
          + /Unlike this article, I don't think it's realistic to assume that drone prices will continue to decline while drone performance goes up -- I think the relevant analogy is the development of fighter aircraft, which saw relatively cheap and unsophisticated aircraft giving way to increasingly sophisticated and expensive models/
     3. Robotic assassination is common and difficult to attribute
        + Small autonomous robots could be configured to inject poison
        + Larger robots could be configured with guns and biometric technology to scan for a particular target and open fire
     4. Mobile robotic IEDs give terrorists some of the same capabilities as precision-guided munitions
        + Currently, only sophisticated nation-states have the ability to deliver explosives to a precise target from many miles away
        + Low-cost autonomous vehicles could give the same capability to non-state actors
        + /Example scenario:/
          + /"Kidnap" a self-driving car which already has authorization to enter a secure area/
          + /Stuff with explosives/
          + /Wait until the staff or the car's owner call for the car/
          + /Result: you have a car-bomb that the target calls for, and grants authorization to get past security measures/
     5. Military power grows disconnected from population size and economic strength
        + Countries with small, elderly populations may field robotic "manpower" that magnifies the impact of their human population
        + Countries that have an advantage in AI will be able to field greater numbers of robotic warfighters, which can offset or even negate unfavorable demographics
     6. Cyberweapons are frequently used to kill
        + More physical systems are linked to the Internet
        + Growth of AI will make it easier to find and exploit vulnerabilities
     7. Most actors in cyberspace will have no choice but to enable relatively high-levels of autonomy
        + Systems that are autonomous will execute and react faster than systems with humans in the loop
        + Need autonomous machines to move at "machine speed"
     8. Unplanned interactions of autonomous systems will cause "flash crashes"
        + Autonomous systems can make decisions much more rapidly than the humans who restrain them
        + Because of this high speed unexpected interactions can spiral out of control rapidly
        + Even systems which normally operate much more reliably than humans will have occasional crashes
        + This is especially worrisome given the adversarial nature of espionage and warfare
          + /What happens when an adversary knows that US banks use certain trading algorithms (via cyber-espionage) and deliberately executes a series of trades to trigger a flash crash?/
          + /What happens when an adversary does the same thing with e.g. a missile defense system?/
     9. Involving machine learning in military systems will create new types of vulnerabilities and cyberattacks that target the training data of those systems
        + Machine learning requires high quality data sets
        + What happens when an adversary "poisons" the training data, so that the system recognizes a friendly asset as hostile, under circumstances that the adversary knows about, but you don't?
        + What happens when an adversary "poisons" the training data so that hostile agents are not recognized at all (again, under circumstances that the adversary controls)
        + Hacking of robotic systems poses the risk of mass fratricide -- large numbers of US troops being attacked by "friendly" autonomous weapons
          + Unexpected environmental interactions
          + Enemy action
          + Simple malfunctions or software errors in central control systems
        + /This goes back to the old saw about machine learning -- the machine is learning, but you don't know *what* it's learning/
        + /We already have attacks that exploit known vulnerabilities in machine learning algorithms (like stickers placed on stop signs which cause machine learning algorithms to misclassify them as speed-limit signs)/
        + /It's not a huge leap to imagine adversaries attempting to deliberately poison training data to inject those kinds of vulnerabilities/
     10. Theft and replication of military and intelligence AI systems *will* result in cyberweapons falling into the wrong hands
         + In aerospace, stealing the blueprints for a weapon does not give you access to the weapons
         + You still need sophisticated manufacturing and materials science to actually build the thing you stole the plans for
         + In cyberwarfare, stealing the source code is both stealing the blueprints for the weapon and the weapon itself
         + Moreover, the negligible cost of modifying and replicating software means that if an adversary has stolen one instance of a weapon, they can build new versions relatively cheaply

** Implications for Information Superiority
   + This section analyzes the impact of artificial intelligence on intelligence systems (spies)
   + Collection and analysis of data
     + US intelligence agencies are currently awash in more data than they can usefully analyze
       + The amount of data created doubles every 24 months
       + The amount of data created in the next two years will be equal to that created in the entire prior history of humanity
       + Many more needles, buried in lots more hay
     + Computer assisted intelligence analysis, leveraging machine learning will soon deliver remarkable capabilities, such as being able to photograph and analyze the entire surface of the earth each day
       + Machines already outperform humans at image recognition
       + These image recognition algorithms are already being used on satellite images
       + Machine learning algorithms are well suited for dealing with unstructured sensor data, so we will see broader applications of them in the future
   + Creation of data and media
     + AI can be used to produce data as well as analyze it
       + Realistically changing facial expressions and speech-related mouth movements of an individual on video in real time 
       + Generating realistic-sounding synthetic voice recordings for individuals
       + Producing realistic fake images based upon text descriptions
       + Producing written news articles based upon structured data
       + Creating a 3D representation of an object based upon one or more 2D representations
       + Automatically produce realistic sounds for a silent video
     + In the future, it will be possible for even amateurs to produce photo/video realistic forgeries at scale
       + Today these fakes can fool the untrained eye/ear
       + In the future, they'll be good enough to even fool some kinds of forensic analysis
     + These forgeries will erode social trust as otherwise reliable evidence becomes uncertain
       + /This will have an impact on so-called "open source" intelligence, which relies on witness recordings with e.g. smartphones/
       + /What do you do when there are as many fake videos coming out from a war zone as real ones?/
       + Evidence will have to be authenticated using cryptographic means
   + Potential transformative scenarios
     1. Supercharged surveillance brings about the end of guerrilla warfare
        + Plausible winner-take-all effect for surveillance, particularly for nation-states
        + Terrorist and guerrilla organizations will struggle to communicate and plan attacks without leaving telltales for AI to pick up
        + Cheaper, more sophisticated sensors will make it difficult for terrorists to move undetected through society
        + /On the other hand, we've discussed above about the potential vulnerabilities of AI/
        + /What happens when the guerrillas discover a flaw in the AI algorithm that allows them to move undetected, or even aids them/
     2. A country with a significant advantage in AI-based intelligence analysis gains a decisive advantage in strategic decision-making and shaping
        + AI has the potential to fuse many sources of data into a single, unified system for supporting decisions
        + Some experts state that the advantage from having such a system could be comparable to the advantage gained by the Allies when they broke the Axis' Enigma and Purple codes
        + /Eh, this assumes that the humans in charge will actually listen to the AI/
        + /They already ignore, in many cases, what their human intelligence services are telling them -- why would they be more inclined to believe AI-powered intelligence services?/
        + /Moreover, this again seems to ignore the potential adversary threat, which is weird because the previous section was all about the adversary threat/
        + /What happens when the other side has an AI too, and their AI is feeding your AI carefully crafted misinformation designed to lure you into a war you can't win?/
     3. Propaganda for authoritarian and illiberal regimes becomes increasingly indistinguishable from truth
        + What happens when state-produced propaganda has the exact same telltales as a samizdat video?
        + Did that terrorist attack really happen?
     4. Democratic and free-press difficulty with fake news gets dramatically worse
        + Right now, fake news is a problem insofar as it fools voters
        + In the future, fake news will be a problem insofar as it fools journalists and policymakers
        + /Joke's on you: whether they believe the news or not has little or no bearing on journalists' willingness to propagate it/
        + /Clickbait is clickbait, and journalists are already more than willing to broadcast fake news even as they know the news is fake or of low quality/
        + /I don't actually think things will get much worse, insofar as I believe that we're already pretty close to a worst case scenario/
     5. Command and Control organizations face persistent social engineering threats
        + Those giving orders will struggle to determine whether their orders are real
        + AI can be used to produced counterfeit DoD directives
        + Fake evidence of war crimes
     6. AI-controlled forged media poses risks for economic and government stability
        + On April 23, 2013 hackers took control of the AP's official Twitter account and tweeted that there had been a terrorist attack on the White House
        + In two minutes, the US stock market lost nearly $136 billion in value, until the hack was revealed
        + This attack could have been much worse if the attackers had access to cheaply-forged "corroborating" photos and videos generated using AI techniques
        + This is not a new threat -- we've seen photos of Syria used to claim that Israel was committing war crimes in Gaza
          + /This means that organizations like Bellingcat will be even more important/
          + /Right now, the standard journalistic procedure is to verify media against itself, since forged media is often not internally self-consistent/
          + /AI allows us to make forged media that displays the same level of internal self-consistency as "real" reporting/
          + /Therefore, it will be more important to verify different pieces of information against each other -- if an event is real, you'll see more than one camera angle, more than one source, etc/
          + /Journalism will become more difficult but I don't think it'll become impossible; if anything Bellingcat serves as an existence proof of what new journalism could look like/
        + Even if governments produce countervailing evidence, they could struggle to squash false understandings in a population
          + /This will be doubly true of government-on-government scenarios/
          + /Example: There is a large conspiracy theory in India that believes that it was actually India which shot down a Pakistani jet during the recent conflict/
          + /This conspiracy theory holds despite there being clear photographic evidence that the jet that was shot down was a MiG-21 (which India flies, but not Pakistan)/

** Implications for Economic Security
   + Innovation supercharger
     + AI has the capacity to improve the pace of innovation and invention itself
       + Automation of scientific experiments -- AIs can be trained to look for correlations, generate hypotheses and test them using robotic equipment
       + Synthesizing findings from thousands of scientific papers -- an AI used natural language processing algorithms to analyze thousands of research papers and found 5 new genes related to neurodegenerative disease
         + /Another [[https://blogs.sciencemag.org/pipeline/archives/2019/07/15/machine-mining-the-literature][example]]: Data-mining scientific literature to find new thermoelectric material candidates/
       + Optimizing engineering designs -- AI can optimize existing designs, such as car engines
     + AI can therefore operate as an "innovation supercharger" allowing nations that are ahead in AI to accelerate their research in other fields
   + Automation and Unemployment
     + The 2016 White House Report on Artificial Intelligence, Automation and the Economy found that automation threatens millions of jobs and that AI driven automation may result in more permanent disruptions than past innovations
       + Speed of economic disruption is much faster
       + Pace of benefits is slower than pace of harms -- jobs are lost today, AI driven benefits arrive tomorrow
       + What happens when a large portion of the workforce (up to a third, by some estimates) becomes unemployable
       + Even during the Great Depression, US unemployment was only 25% -- 1/3 unemployment is something that we've never experience
         + /I'm skeptical/
         + /We have to remember that unemployment only counts those who are out of work and are *actively looking* for a new job/
         + /My hypothesis is that "unemployment", as defined above, has a hard cap of about 25% (maybe less, after analyzing data from the Great Recession)/
         + /Once unemployment goes higher than that, people start dropping out of the labor force/
       + What happens when AI-driven mechanization makes large numbers of wokers uncompetitive at *any* price, much like what happened to horses after gasoline/diesel engines were developed?
         + Human farm laborers got jobs in factories when farms became mechanized
         + Horses could not
     + If automation renders large numbers of workers permanently displaced, wealthy countries could encounter the same "resource curse" problem that poor countries have
       + "Resource curse" -- large deposits of natural resources in countries with poor governing institutions act as a brake on development rather than an accelerant
         + Extractive industries promote inequality and poor governance
           + Industries such as mining tend to be capital-intensive and labor-light
           + Small group of capital owners extract almost all of the value
         + Redistribution of revenues risks corruption
           + While the government *can* tax extractive industries in order to provide public goods, in practice, this leads to corruption
           + Capital owners identify who is taxing them and lobby and co-opt the institutions which serve to regulate and tax them
           + Inequality promotes civil conflict
       + AI has the potential to turn *every* industry into a capital-intensive/labor-light industry like mining
   + Potential transformative scenarios
     1. Automation induced "resource curse" plagues developed economies
        + In the first industrial revolution, initially most of the returns went to capital over labor
        + Workers were only able to capture benefits of industrial revolution when they organized into units (unions) which were able to affect production
        + In "resource curse" countries, the vast majority of workers lack the ability to meaningfully impact economic production -- only the small fraction of workers in the extractive industry have the power to affect production
        + Therefore, the owners of capital only redistribute the minimum amount needed to establish political or military governing coalitions
        + If automation renders large swathes of the labor force permanently redundant, similar dynamics could take hold for highly automated economies
     2. A country with a lead in AI develops a self-reinforcing technological and economic edge
        + AI improves innovation in every other sector of the economy
        + This can lead to a breakaway scenario where a small edge in AI today compounds into an unassailable lead after a few decades
        + Look at how a small edge in industrialization allowed Great Britain to conquer 25% of the globe
        + /This assumes that AI innovation can't be stolen/
        + /Great Britain was able to conquer the world because of a combination of institutional innovation (joint-stock limited-liability corporations) and technological innovation/
        + /While the technological innovation could be stolen, the institutional innovations could not, and IMHO that's why Britain won/
     3. AI enabled sabotage emerges as a new type of weapon
        + As seen above, even today, fake news can roil markets
        + What happens when an AI-armed adversary plants a specific news stories in order to create a "flash crash"?

* Part 2: Learning from Prior Transformative Technology Cases
  + This section analyzes previous "transformative" military innovations to see if we can find some prior analogues for the impact that AI will have on military innovation
  + Analyze the following technologies:
    + Nuclear
    + Aerospace
    + Cyber
    + Biotech

** Key Technology Management Aspects
   + Each of the above technologies was transformative for US national security
   + However, each had different scientific and economic circumstances, which affected the optimal approach for managing them
   + Evaluate each technology across the following criteria
     1. Destructive potential
        + How much potential destruction
        + How assured is the destruction
        + Can the destructive potential be demonstrated in a "safe" setting
     2. Cost profile
        + How much does it cost to develop the weapon at scale?
        + How much does it cost to use the weapon?
        + Does production require large fixed assets?
     3. Complexity profile?
        + What kinds of technical expertise are required to develop the technology
        + Once developed, how difficult is the technology to use?
        + Is this expertise a matter of formal knowledge (mathematics) or tacit knowledge (manufacturing excellence)?
     4. Military/Civilian dual-use potential
        + Does experience with the technology in the civilian sphere help with developing the technology for military uses?
        + Do companies that produce for civilian use also tend to produce for the military?
     5. Difficulty of espionage and monitoring
        + Is it easy for adversaries to monitor the progress of a military development rpogram
        + Is the technology easily reverse-engineered?
   + Evaluation of previous revolutionary technologies
     + Nuclear
       + Destructive potential: immense and easily demonstrated
       + Cost profile: Massive; early nuclear development took a nontrivial fraction of GDP; even today the development of nuclear weapons is immensely expensive
       + Complexity profile: early nuclear weapons required fundamental breakthroughs in materials science and engineering; even today the manufacture of nuclear weapons requires significant specialized expertise
       + Military/Civilian Dual Use potential: nuclear medicine and nuclear power both carry significant proliferation risk
       + Difficulty of espionage and monitoring: Aerospace ISR, signals intelligence and radioactive tracing allow for monitoring
     + Aerospace
       + Destructive potential: only a massive number of planes can threaten the existence of a state; attacks are relatively easy to defend against
       + Cost profile: in 1945 a fighter aircraft was roughly 50x the cost of a civilian car
       + Complexity profile: By World War 2, only relatively advanced economies could compete to build state-of-the-art aerospace technology
       + Military/Civilian dual-use potential: early airliners were converted bombers, and could have been re-converted back to a military role
       + Difficulty of espionage and monitoring: Aircraft factories appear similar to other factories and can be easily concealed
     + Cyber
       + While cyber can inflict physical damage as control systems are connected to hackable electronic networks, the destructive potential of cyber is not always assured
       + Cost profile: Even non-state actors can afford relatively sophisticated cyber capabilities; no specialized equipment required to conduct cyber-attacks
       + Complexity profile: Low-end attacks require a minimum of skill; high-end attacks require state-level skill and human resources
       + Military/Civilian dual-use potential: commercial systems can be repurposed to carry out cyber-attack; military and civilian roles require almost identical skillsets
       + Difficulty of espionage and monitoring: even sensitive networks are routinely infiltrated without detection
     + Biotech
       + Destructive potential: natural pandemics have killed millions, bioweapons could too
       + Cost profile: Equipment is cheap, but requires relevant expertise to use
       + Complexity profile: At first relatively few people had the necessary expertise to develop bioweapons
       + Military/Civilian dual-use potential: the equipment needed to develop bioweapons is the same as the equipment needed to conduct pharmaceutical R&D
       + Difficulty of espionage/monitoring: Bioweapons facilities are difficult to distinguish from commercial pharmaceutical labs

** Government Technology Management Approach
   + Characterize how the US government has managed the above technologies
   + Nuclear: all-out government led development and utilization
     + Extraordinary levels of spending, both for initial development and ongoing maintenance
     + Initially, all nuclear technology was treated as classified government property -- was illegal to hold patents on nuclear technology
   + Aerospace: government led public/private partnership
     + Government provides R&D funding and acts as anchor customer
     + However, actual production is done by private corporations
     + Government restricts some technologies with export restrictions and classification
   + Cyber: government "seeding and harvesting"
     + Government was heavily involved in the development of early computer networks, but has ceded almost all control to private entities
     + Government role in aiding cybersecurity and and offensive cyber-operations, but has a hands-off role everywhere else
   + Biotech: voluntary restraint
     + US government ends its bioweapons programs in 1969 with the ratification of the Biological Weapons Convention
     + USSR bioweapons development continues through end of Cold War
     + Voluntary restrictions on DNA technology adopted by US and EU to make bioweapons more difficult to develop

** Government management approach "scorecard"
   + How did the government's appropach to managing the new technology fare on the following three metrics:
     + Preserve US technological leadership
     + Support peaceful uses of the technology
     + Manage catastrophic risks
   + Nuclear
     + Preserve US technological leadership: Partial success
       + US had more nukes and developed nukes first
       + Did not give the US a sustainable advantage
       + Advantages were eroded by espionage
     + Support peaceful use: partial success
       + Nuclear weapons gave way to nuclear power and nuclear medicine
       + Benefits were not as high as expected and proliferation risks were underestimated
     + Manage catastrophic risks: partial failure
       + No accidental detonations
       + Many close calls and near-misses
   + Aerospace
     + Preserve US technological leadership: success
       + US has been the undisputed leader of developing aerospace tech, aside for some brief periods between World War 1 and World War 2
     + Support the peaceful use of technology: success
       + After World War 2, US was a leader in applying military innovations to air transport
     + Manage catastrophic risks: success
       + Main risks are crashes and and attacks from superior air forces, both of which have been responded to effectively
   + Cyber
     + Preserve US technological leadership: success
       + US has leading cyber capabilities
       + More difficult to preserve an advantage in cyber, but the US has done it
     + Support the peaceful use of technology: partial success
       + US organizations lead the world in computing
       + However, US government and organizations are far too vulnerable to cyber-attack
     + Manage catastrophic risks: partial failure
       + US developed advantage in offensive cyber operations
       + Ignored cyber-defense, leading to asymmetric vulnerability
   + Biotech
     + Preserve US technological leadership: N/A
       + US voluntarily disbanded bioweapons program
       + Said nuclear deterrence was sufficient
     + Support peaceful use of technology: success
       + US has a world-leading biotech industry
       + Strong government support for peaceful biotech R&D
     + Manage catastrophic risk: partial success
       + No major bioweapons attacks
       + UN Biological Weapons Convention was partially successful at delaying research until risks were better understood

** AI Technology Profile: A Worst Case Scenario?
   + AI presents a uniquely difficult challenge
   + Destructive potential: High
     + At a minimum, AI will dramatically augment autonomous weapons and espionage capabilities
     + At a worst case, AI presents an existential risk to humanity
       + /Here they cite Bostrom, which I find to be remarkable/
   + Cost profile: diverse, but potentially low
     + Developing cutting-edge AI technology carries a significant cost
     + /Though, compared to the cost of developing nuclear weapons for the first time, even Google's spending on AI looks pretty paltry/
     + However, due to open-source nature of AI development, small teams can readily leverage AI software once it is developed
     + Leaked copies of AI software might be virtually free
     + /This is where I oppose OpenAI's policy of deciding what's best/
     + /In practice, keeping software closed \(=\) giving said software to the NSA
   + Complexity profile: diverse, but potentially low
     + Advancing the state of the art in AI requires elite talent
     + However, it requires much less skill to apply AI to existing problems
     + As AI software improves, it will likely require less skill to use
   + Military/Civilian Dual-Use potential: High
     + Militaries and civilian AI research are competing for exactly the same talent pool
     + However, some military-related applications of AI require non-AI expertise to apply
   + Difficulty of espionage and monitoring: High
     + Significant overlap between civilian and military AI development makes it impossible to determine whether adversaries have advanced their military AI systems
     + Few physical markers of AI systems
     + Total numbers of state-of-the-art AI systems will be significantly higher than nuclear or even aerospace
     + Difficult to assess the potential of AI-enhanced weapons systems without direct access

** Lessons Learned
   + What lessons can we learn from past advances in technology with national-security implications?
   + Lesson 1: Radical technology change begets radical government policy ideas
     + The transformative nature of nuclear weapons led the US government to consider some pretty radical ideas
       + Enacted: giving one person the sole authority to start nuclear war -- the US president was given sole authority to start a conflict that could end the United States
       + Considered: internationalizing nuclear weapons under the authority of the United Nations (the "Baruch Plan")
       + Enacted: Voluntarily sharing atomic weapons technology with allies (something that the US did not do with other weapons systems)
       + Considered: Using atomic arms to annihilate adversaries, including the Soviet Union, before they had a chance to develop atomic arms of their own
         + /The Soviet spying on the US atomic weapons program rendered this question moot because the Soviet Union developed its own atomic weapons before the US had a chance to build up much of a lead/
       + Enacted: Voluntarily restricting weapons development using arms control frameworks
         + /This isn't as unprecedented as it's made out to be -- the major powers agreed to restrict battleship development under the Washington and London naval treaties before World War 2/
     + The 25th Amendment, clarifying Presidential succession, was motivated in large part by the need to make it absolutely clear who had the authority to launch a nuclear counterstrike in the event that a nuclear strike incapacitated or killed the President and the Vice President
     + Aerospace technology led to the creation of the US Air Force, so that the military could better invest in transformative aviation and space technology
     + The full impact of AI is unclear, as is the speed at which AI will arrive
     + So far, AI looks to be a transformative military technology
     + However, some, such as Bostrom, argue that AI's potential to recursively self-improve makes it a threat to the entire species
     + If that is the case, government will consider measures as radical as in the early days of nuclear weapons
     + The larger and more visible the impacts of AI become, the more governments will become amenable to radical policy measures
   + Lesson 2: Arms races are sometimes unavoidable, but can be managed
     + Fears of aerial bombing led to a treaty banning the combat use of aircraft, but this treaty was rapidly abandoned in World War I
       + The 1899 Hague Convention (which was a predecessor to the Geneva Convention) specified a five-year moratorium on the development of aircraft for military purposes
       + The intent was to make this moratorium permanent, but after the 5-year moratorium had passed, governments appreciated the nature of aircraft too well to allow a permanent ban
       + By the time World War 1 broke out, the only real limit on the military use of aircraft was technology
       + Every belligerent power's capital, except for Rome, was bombed from the air
     + The application of AI to warfare is as likely to be as irresistible as the application of aircraft to war
       + Supremacy in aerospace technology became synonymous with military supremacy in general
       + Similarly, in business, companies that have mastered AI-related technologies are outcompeting companies that are farther behind
       + Military leaders see a similar dynamic developing for AI-enhanced weapons systems
         + /This is why China is investing so heavily in AI -- the Chinese leadership sees AI as a "leapfrog" technology that will allow it to jump past Western technological superiority in conventional weapons/
     + While outright bans on AI technology in the national security sector are unrealistic, the more modest goal of ensuring safe and effective technology management can and must be pursued
       + While bans on the military application of nuclear and aerospace technology fell apart, world powers did manage to negotiate arms control frameworks that limited the uses of these technologies
       + We can, and should negotiate a similar thing for AI
   + Lesson 3: Governments must both promote and restrain commercial activity
     + Failure to recognize dual-use technolgy can cost lives
       + Rolls Royce developed the world's first commercially viable jet engine: the "Nene"
       + Seeking export revenue, they sold 15 models of the Nene to the Soviet Union
         + /When the Soviets initially sought permission from Stalin to purchase these engines, Stalin initially demurred, remarking, "What fool will sell us his secrets?"/
         + /As it turns out.../
       + The Soviet Union reverse-engineered the engine into the Klimov VK-1, which was turned into the Klimov RD-45, which was the engine that powered the MiG-15
       + The MiG-15 was the world's first production trans-sonic fighter and it quickly dominated the skies over Korea before it was countered by the US' F-86.
       + As a result of the MiG-15, the US expanded its classification system to cover aerospace technology and restricted the sales of technologies deemed important to national defense
       + /I wonder which piece of open-source AI technology will be looked back upon as the "Nene" of our time/
       + /Stalin, if he were alive today, would be amazed -- they don't even sell their secrets, they give them away!/
     + Having the lagest and most advanced digital technology industry in the world is an advantage for the United States, but it needs to reconcile commercial and national security interests
     + Unlike with nuclear and aerospace, the US government is not the largest customer of AI technology, so it doesn't have the same sort of market leverage that it had with aerospace
     + Political relations between the US goverment and the technology industry are strained
       + Ongoing conflict over encryption technology
       + Edward Snowden revelations
       + Statements made by political leaders re: the technology industry
   + Lesson 4: Government must formalize goals for safety and provide resources
     + In each of the four transformative technologies studied above (nuclear, aerospace, cyber, and biotech), national security policymakers faced tradeoffs between security and performance
     + Government was more likely to respond appropriately to some risks than others
     + What is worrisome is the long lead times between the identification of risk and the implementation of mitigations for that risk
       + Defense Secretary Robert McNamara said that the fact that the US had not experienced a catastrophic nuclear weapons accident was attributable as much to luck as it was to careful preparation
       + Most cybersecurity experts feel that the lack of a catastrophic cyber-attack has as much to do with luck and deterrence as it does with the US hardening its information systems
     + However, not all communities had such a reactive approach to safety
       + US nuclear submarine community has never lost a submarine to reactor failure (/however, the US submarine community *has* lost submarines to other forms of failure/)
       + Aerospace community delivered both improved safety and technological advancements (/Is the Boeing 737 Max a sign of worrying backsliding in that regard, as cyber-norms infect the aerospace sector?/)
     + Safety outcomes improved when government created formal organizations tasked with improving the safety of their respective technology domains
       + Nuclear weapons safety department at Sandia National Labs
       + Centers for Disease Control and Prevention
       + Federal Aviation Administration
       + /US is *slowly* moving to improve its cybersecurity through the creation of the CISA: Cybersecurity and Infrastructure Security Agency/
     + As the US increasingly integrates artificial intelligence into its commercial and government systems, the US government should stand-up a formal R&D organization tasked with investigating AI safety across the entire government and commercial AI portfolio
   + Lesson 5: As a technology changes, so does the US' national interest
     + The declining cost and complexity of bioweapons led the US to change its policy from aggressive development to voluntary restraint
       + At the end of World War 2, the US believed that bioweapons would be complex to develop and thus only available to powerful states
       + Spent a significant amount researching mass-production, storage and dispersal methods
       + However, by the 1960s, technological progress made it possible for bioweapons to be comparative in destructive potential to nuclear weapons and available to weaker states that lacked the ability to develop nuclear weapons
       + As a result, in an effort to influence global norms, the US renounced the entire category of weapons, something which it had never done before
     + The US has a strategic interest in shaping the cost, complexity and offense/defense balance of emerging strategic technologies
       + The US unilaterally disarmed its bioweapons program because it judged that its national interests were better served by preventing other states from developing bioweapons that they were by the US having bioweapons itself
       + The US has a strategic interest in the attributes of emerging military technologies
         + US has a much larger economy than its adversaries
         + US is better off if emerging military technologies are expensive, complex and hard to develop
         + US is better off the difference between state-of-the-art and cheaper/older alternatives is large and hard to close
         + /Gotta say, AI isn't looking good on either of those metrics/
     + The case of stealth aircraft shows that careful strategic investments can alter the offense/defense balance in a field and build a long-lasting technological edge
       + In 1978, Soviet-made SAMs shot down 109 Israeli aircraft in the Yom Kippur war
       + As a result, the US estimated that NATO air forces would be decimated by Soviet air-defense systems in the case of a European conflict
       + The US therefore embarked on a series of strategic investments in developing aircraft that were able to evade radar (a.k.a. stealth)
       + With the debut of the F-117, the strategic balance tipped back in favor of the US's offensive capabilities
       + Most surprisingly, the initial research into radar absorption and deflection took place in the Soviet Union in the early '60s
       + Despite having a 9-year head start the Soviet Union failed to invest in developing its theoretical insights into workable technology and therefore never successfully fielded stealth aircraft or radars capable of detecting US stealth aircraft
     + The US should consider how it can shape the technological profile of military and intelligence applications of AI
       + AI has the /potential/ to be a worst case outcome from a technology management perspective, but that doesn't mean that a worst case outcome is inevitable
       + As the US pursues AI related defense technologies, it should ask itself whether these technologies will produce a sustainable military advantage for the US or whether they will merely accelerate the acquisition of similar capabilities by other actors

* Part 3: Recommendations For Artificial Intelligence and National Security

** Preserving US Technological Leadership

*** Recommendation 1: DoD should conduct AI focused wargames to identify potential disruptive military innovations
    + Background: Disruptive innovation theory
      + 2 kinds of innovation: disruptive and sustaining
      + Sustaining innovation: 
        + Making better products that can be sold to existing customers
        + Existing incumbents usually beat new entrants
      + Disruptive innovation:
        + Simpler, more convenient product
        + Sells for less money
        + Appeals to a new or unattractive customer set, which nevertheless is much larger than the set of customers of the market being disrupted
        + New entrants usually beat incumbents
        + /Note: it's disputed how true Christensen's theory of disruptive innovation is; in his book all the "disruptors" eventually went out of business whereas his incumbent firms (Seagate, Caterpillar, etc.) either acquired the disruptors or copied their innovations and drove them from the industry/
    + Disruptive innovation theory applies to military domains
      + US, as the world's leading military power, is in the position of the incumbent
      + Competes by sustaining and improving its already extradordinary military capabilities
      + Competitors have to figure out how to compete with the US while having fewer advantages
      + Example of disruptive military innovation: Improvised Explosive Device (IED)
      + Even though the IED was significantly inferior to US military technology, it still posed a significant threat
    + Advances in AI will enable new, disruptive innovations for military power
      + A $1000 quadcopter might appear useless since its capabilities are inferior in every way to existing manned and unmanned systems
      + However, it allows low-capability militaries and non-state actors to unlock some of the same capabilities (such as advanced reconaissance and long-range precision delivery of explosives) which are currently only available to advanced militaries
      + /Quadcopters will start out being inferior, but due to the fact that they're cheaper and easier to iterate upon, swarms of quadcopters may end up being as capable or even more capable than today's high-end military platforms, much like fleets of commodity PC hardware can equal or surpass the capabilities of mainframes with specialized processors/
    + Recommendation: 
      + DoD should fund war-games and red-team exercises designed to identify potentially disruptive AI technologies
      + Identify the potential benefits of AI to:
        + Powerful nation-states
        + Middle-powers
        + Non-state actors

*** Recommendation 2: DoD should fund long-term strategic analyses of AI technology and its implications
    + Beyond military wargames, the US needs prolonged strategic thinking about AI and its implications
      + There is much about AI that is unprecedented
      + We need a body that will conduct detailed, long-term strategic analyses of AI technology like what the RAND corporation did for nuclear strategy
    + This body will, at a minimum need to study the following questions:
      + What is the first-mover advantage in developing AI? Can fast-followers compete?
      + What commercial AI technologies have dual-use potential?
      + What investments in AI technology could affect the offense/defense balance in a future conflict? What balance should the US prefer?
      + What AI investments would extend the advantages of powerful states over middle-powers and non-state actors?
      + How will the growth of artificial intelligence affect the balance of *economic* power?
      + How might artificial general intelligence happen? How can the US plan for it?

